{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Collecting Text Data from the Web</h1>\n",
    "<br>\n",
    "<h2>Collecting Data by Scraping Web Pages</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Insert a new cell and add the following code to import the <code>BeautifulSoup</code> library</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Then, we create an object of the <code>BeautifulSoup</code> class and pass the location of the HTML file to it</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('data/sample_doc.html'), 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Add the following code to check the <code>text</code> contents of the <code>sample_doc.html</code> file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n A sample HTML Page \\n\\n\\nI am staying at  Mess on No. 72, Banamali Naskar Lane, Kolkata. \\nSherlock  stays at 221B, Baker Street, London, UK. \\nHamlet said to Horatio,   There are more things in heaven and earth, Horatio,  Than are dreamt of in your philosophy. \\n A table denoting details of students\\n\\n\\nname\\nqualification\\nadditional qualification\\nother qualification\\n\\n\\nGangaram\\nB.Tech\\nNA\\nNA\\n\\n\\nGanga\\nB.A.\\nNA\\nNA\\n\\n\\nRam\\nB.Tech\\nM.Tech\\nNA\\n\\n\\nRamlal\\nB.Music\\nNA\\nDiploma in Music\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To check the <code>address</code> tag, we insert a new cell and add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<address> Mess on No. 72, Banamali Naskar Lane, Kolkata.</address>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To locate all the <code>address</code> tags within the given content, write the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<address> Mess on No. 72, Banamali Naskar Lane, Kolkata.</address>,\n",
       " <address>221B, Baker Street, London, UK.</address>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To check <code>quotes</code> within the content, we write the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<q> There are more things in heaven and earth, Horatio, <br/> Than are dreamt of in your philosophy. </q>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To check all the <code>bold</code> items, we write the following command</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>Sherlock </b>, <b>Hamlet</b>, <b>Horatio</b>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To check all the contents inside the <code>table</code> tag, we write the following command</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We can also view the content of <code>table</code> by looping through it. Insert a new cell and add the following code to implement this</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[<td>Gangaram</td>, <td>B.Tech</td>, <td>NA</td>, <td>NA</td>]\n",
      "[<td>Ganga</td>, <td>B.A.</td>, <td>NA</td>, <td>NA</td>]\n",
      "[<td>Ram</td>, <td>B.Tech</td>, <td>M.Tech</td>, <td>NA</td>]\n",
      "[<td>Ramlal</td>, <td>B.Music</td>, <td>NA</td>, <td>Diploma in Music</td>]\n"
     ]
    }
   ],
   "source": [
    "for row in table.find_all('tr'):\n",
    "    columns = row.find_all('td')\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We can also locate specific content in the table. If we want to locate the value of the third row and the second column, we write the following command</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>M.Tech</td>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.find_all('tr')[3].find_all('td')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Requesting Content from Web Pages</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Use the <code>requests</code> library to request the content of a book available online with the following set of commands</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.post('https://www.gutenberg.org/files/766/766-0.txt')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, 200 indicates that we received a proper response from the URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To locate the text content of the fetched file, write the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ï»¿The Project Gutenberg EBook of David Copperfield, by Charles Dickens\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook or online at www.gutenberg.org\\r\\n\\r\\n\\r\\nTitle: David Copperfield\\r\\n\\r\\nAuthor: Charles Dickens\\r\\n\\r\\nRelease Date: December, 1996  [Etext #766]\\r\\nPosting Date: November 24, 2009\\r\\nLast Updated: September 25, 2016\\r\\n\\r\\nLanguage: English\\r\\n\\r\\nCharacter set encoding: UTF-8\\r\\n\\r\\n*** START OF THIS PROJECT GUTENBERG EBOOK DAVID COPPERFIELD ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nProduced by Jo Churcher\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nDAVID COPPERFIELD\\r\\n\\r\\n\\r\\nBy Charles Dickens\\r\\n\\r\\n\\r\\n\\r\\n               AFFECTIONATELY INSCRIBED TO\\r\\n               THE HON.  Mr. AND Mrs. RICHARD WATSON,\\r\\n               OF ROCKINGHAM, NORTHAMPTONSHIRE.\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\n\\r\\n     I.      I Am Born\\r\\n     II.     I Observe\\r\\n     III.    I Have a Change\\r\\n     IV.     I Fall into Disgrace\\r\\n     V.   '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now we'll write the fetched content to a text file. To do that, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033139"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"data/David_Copperfield.txt\", 'w', encoding=\"utf-8\").write(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now we'll make use of the <code>urllib3</code> library to request the content of the book, available online. Add the following code to do so</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'\\xef\\xbb\\xbfThe Project Gutenberg EBook of David Copperfield, by Charles Dickens\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook or online at www.gutenberg.org\\r\\n\\r\\n\\r\\nTitle: David Copperfield\\r\\n\\r\\nAuthor: Charles Dickens\\r\\n\\r\\nRelease Date: December, 1996  [Etext #766]\\r\\nPosting Date: November 24, 2009\\r\\nLast Updated: September 25, 2016\\r\\n\\r\\nLanguage: English\\r\\n\\r\\nCharacter set encoding: UTF-8\\r\\n\\r\\n*** START OF THIS PROJECT GUTENBERG EBOOK DAVID COPPERFIELD ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nProduced by Jo Churcher\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nDAVID COPPERFIELD\\r\\n\\r\\n\\r\\nBy Charles Dickens\\r\\n\\r\\n\\r\\n\\r\\n               AFFECTIONATELY INSCRIBED TO\\r\\n               THE HON.  Mr. AND Mrs. RICHARD WATSON,\\r\\n               OF ROCKINGHAM, NORTHAMPTONSHIRE.\\r\\n\\r\\n\\r\\nCONTENTS\\r\\n\\r\\n\\r\\n     I.      I Am Born\\r\\n     II.     I Observe\\r\\n     III.    I Have a Change\\r\\n     IV.     I Fall into Disgrace\\r\\n     V.   '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "rr = http.request('GET', 'https://www.gutenberg.org/files/766/766-0.txt')\n",
    "rr.data[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Once the content is fetched properly, we write it to a text file using the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033139"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('data/David_Copperfield_new.txt', 'wb').write(rr.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Analyzing the Content of Jupyter Notebooks (in HTML Format)</h1>\n",
    "<br>\n",
    "In this exercise, we will analyze the content of t<code>ext_classifier.html</code>. Here, we will focus on things such as counting the number of images, listing the packages that have been imported, and checking models and their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nCh3_Activity7_Developing_end_to_end_Text_Classifiers\\n\\n\\n\\n    /*!\\n*\\n* Twitter Bootstrap\\n*\\n*/\\n/*!\\n *'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(open('data/text_classifier.html'), 'html.parser')\n",
    "soup.text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To count the number of images, we make use of the <code>img</code> tag</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('img'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To list all the packages that are imported, we add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas',\n",
       " 'pd',\n",
       " 'seaborn',\n",
       " 'sns',\n",
       " 'matplotlib.pyplot',\n",
       " 'plt',\n",
       " 're',\n",
       " 'string',\n",
       " 'nltk',\n",
       " 'nltk.corpus',\n",
       " 'nltk.stem',\n",
       " 'sklearn.feature_extraction.text',\n",
       " 'sklearn.model_selection',\n",
       " 'pylab',\n",
       " 'nltk',\n",
       " 'warnings',\n",
       " 'sklearn.metrics',\n",
       " 'sklearn.linear_model',\n",
       " 'sklearn.ensemble',\n",
       " 'xgboost']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.get_text() for i in soup.find_all('span',attrs={\"class\":\"nn\"})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To extract the models and their performances, look for the <code>h2</code> and <code>div</code> tags with the <code>class</code> attribute</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Logistic Regression¶\n",
      "\n",
      "confusion matrix: \n",
      " [[28705   151]\n",
      " [ 1663  1396]]\n",
      "\n",
      "accuracy:  0.943161522794924\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     28856\n",
      "           1       0.90      0.46      0.61      3059\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     31915\n",
      "   macro avg       0.92      0.73      0.79     31915\n",
      "weighted avg       0.94      0.94      0.93     31915\n",
      "\n",
      "\n",
      "Area under ROC curve for validation set: 0.911224422146723\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Model:  Random Forest¶\n",
      "\n",
      "confusion matrix: \n",
      " [[28856     0]\n",
      " [ 2990    69]]\n",
      "\n",
      "accuracy:  0.9063136456211812\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     28856\n",
      "           1       1.00      0.02      0.04      3059\n",
      "\n",
      "   micro avg       0.91      0.91      0.91     31915\n",
      "   macro avg       0.95      0.51      0.50     31915\n",
      "weighted avg       0.92      0.91      0.86     31915\n",
      "\n",
      "\n",
      "Area under ROC curve for validation set: 0.8531297215658813\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Model:  XG-Boost¶\n",
      "\n",
      "confusion matrix: \n",
      " [[28754   102]\n",
      " [ 1965  1094]]\n",
      "\n",
      "accuracy:  0.935234215885947\n",
      "\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     28856\n",
      "           1       0.91      0.36      0.51      3059\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     31915\n",
      "   macro avg       0.93      0.68      0.74     31915\n",
      "weighted avg       0.93      0.94      0.92     31915\n",
      "\n",
      "\n",
      "Area under ROC curve for validation set: 0.7768946011682453\n",
      "\n",
      "\n",
      "---------------------------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for md, i in zip(soup.find_all('h2'), soup.find_all('div', attrs={\"class\":\"output_subarea output_stream output_stdout output_text\"})):\n",
    "    print(\"Model: \", md.get_text())\n",
    "    print(i.get_text())\n",
    "    print(\"---------------------------------------------------------\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extracting Information from an Online HTML Page</h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity, we will extract data about Rabindranath Tagore from a Wikipedia page. After extracting the data, we will analyze things such as the list of headings under the Works section, the list of his works, and the list of universities named after him.\n",
    "<br>\n",
    "<br>\n",
    "Read the wikipedia page about Rabindranath Tagore. Extract the following information from it:\n",
    "<br>\n",
    "<ul>\n",
    "    <li>List of headings under Section Works.</li>\n",
    "    <li>List of his Works.</li>\n",
    "    <li>List of Universities named after him.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import the <code>requests</code> and <code>BeautifulSoup</code> libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fetch the Wikipedia page from https://bit.ly/1ZmRIPC the <code>get</code> method of the <code>requests</code> library.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('https://en.wikipedia.org/wiki/Rabindranath_Tagore')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Convert the fetched content into <code>HTML</code> format using an <code>HTML</code> parser</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print the list of headings under the Works section</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama\n",
      "Short_stories\n",
      "Novels\n",
      "Poetry\n",
      "Songs_(Rabindra_Sangeet)\n",
      "Art_works\n"
     ]
    }
   ],
   "source": [
    "for ele in soup.find_all('h3')[:6]:\n",
    "    tx = BeautifulSoup(str(ele),'html.parser').find('span', attrs={'class':\"mw-headline\"})\n",
    "    if tx is not None:\n",
    "        print(tx['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h3><span class=\"mw-headline\" id=\"Drama\">Drama</span></h3>,\n",
       " <h3><span class=\"mw-headline\" id=\"Short_stories\">Short stories</span></h3>,\n",
       " <h3><span class=\"mw-headline\" id=\"Novels\">Novels</span></h3>,\n",
       " <h3><span class=\"mw-headline\" id=\"Poetry\">Poetry</span></h3>,\n",
       " <h3><span id=\"Songs_.28Rabindra_Sangeet.29\"></span><span class=\"mw-headline\" id=\"Songs_(Rabindra_Sangeet)\">Songs (Rabindra Sangeet)</span></h3>,\n",
       " <h3><span class=\"mw-headline\" id=\"Art_works\">Art works</span></h3>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h3')[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print the list of works by Tagore</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bhānusiṃha Ṭhākurer Paḍāvalī, (Songs of Bhānusiṃha Ṭhākur), 1884\n",
      "]\n",
      "[Manasi, (The Ideal One), 1890\n",
      "]\n",
      "[Sonar Tari, (The Golden Boat), 1894\n",
      "]\n",
      "[Gitanjali, (Song Offerings), 1910\n",
      "]\n",
      "[Gitimalya, (Wreath of Songs), 1914\n",
      "]\n",
      "[Balaka, (The Flight of Cranes), 1916\n",
      "]\n",
      "[Valmiki-Pratibha, (The Genius of Valmiki), 1881\n",
      "]\n",
      "[Kal-Mrigaya, (The Fatal Hunt), 1882\n",
      "]\n",
      "[Mayar Khela, (The Play of Illusions), 1888\n",
      "]\n",
      "[Visarjan, (The Sacrifice), 1890\n",
      "]\n",
      "[Chitrangada, (Chitrangada), 1892\n",
      "]\n",
      "[Raja, (The King of the Dark Chamber), 1910\n",
      "]\n",
      "[Dak Ghar, (The Post Office), 1912\n",
      "]\n",
      "[Achalayatan, (The Immovable), 1912\n",
      "]\n",
      "[Muktadhara, (The Waterfall), 1922\n",
      "]\n",
      "[Raktakarabi, (Red Oleanders), 1926\n",
      "]\n",
      "[Chandalika, (The Untouchable Girl), 1933\n",
      "]\n",
      "[Nastanirh, (The Broken Nest), 1901\n",
      "]\n",
      "[Gora, (Fair-Faced), 1910\n",
      "]\n",
      "[Ghare Baire, (The Home and the World), 1916\n",
      "]\n",
      "[Yogayog, (Crosscurrents), 1929\n",
      "]\n",
      "[Jivansmriti, (My Reminiscences), 1912\n",
      "]\n",
      "[Chhelebela, (My Boyhood Days), 1940\n",
      "\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "table = soup.find_all('table')[1]\n",
    "for row in table.find_all('tr'):\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns)>0:\n",
    "        columns = columns[1:]\n",
    "        print(BeautifulSoup(str(columns), 'html.parser').text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Print the list of universities named after Tagore</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rabindra Bharati University, Kolkata, India.',\n",
       " 'Rabindra University, Sahjadpur, Shirajganj, Bangladesh.[1]',\n",
       " 'Rabindranath Tagore University, Hojai, Assam, India',\n",
       " 'Rabindra Maitree University, Courtpara, Kustia,Bangladesh.[2]',\n",
       " 'Bishwakabi Rabindranath Tagore Hall, Jahangirnagar University, Bangladesh',\n",
       " 'Rabindra Nazrul Art Building, Arts Faculty, Islamic University, Bangladesh',\n",
       " 'Rabindra Library (Central), Assam University, India',\n",
       " 'Rabindra Srijonkala University, Keraniganj, Dhaka, Bangladesh']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[BeautifulSoup(str(i),'html.parser').text.strip() for i in soup.find('ol') if i!='\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extracting and Analyzing Data Using Regular Expressions</h2>\n",
    "<br>\n",
    "In this activity, we will extract data from Packt's website. The data to be extracted includes FAQs and their answers, phone numbers, and emails. Follow these steps to implement this activity\n",
    "<br>\n",
    "<br>\n",
    "Extract the following from Packt website <br>\n",
    "<ul>\n",
    "    <li>FAQs and their answers from \n",
    "        <a href='https://www.packtpub.com/books/info/packt/faq'>\n",
    "            https://www.packtpub.com/books/info/packt/faq</a>.</li>\n",
    "    <li>Phone numbers and emails from\n",
    "        <a href='https://www.packtpub.com/books/info/packt/terms-and-conditions'>\n",
    "            https://www.packtpub.com/books/info/packt/terms-and-conditions \n",
    "        </a></li>\n",
    "</ul>\n",
    "<b>Import the necessary libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get('https://www.packtpub.com/books/info/packt/faq')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extract data from https://bit.ly/2uw0Avf the urllib3 library</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http = urllib3.PoolManager()\n",
    "rr = http.request('GET', 'https://www.packtpub.com/books/info/packt/faq')\n",
    "rr.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fetch questions and answers from the data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(rr.data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How can I download eBooks?',\n",
       " 'What format are Packt eBooks?',\n",
       " 'Can I send an eBook to my Kindle?',\n",
       " 'How can I download code files for eBooks and Videos?',\n",
       " 'How can I download Videos?',\n",
       " 'How can I gift an eBook/Video/Course/Packt subscription?',\n",
       " 'Can I send an eBook to my Kindle?',\n",
       " 'What are the different types of courses available on Packt website?',\n",
       " 'Which courses are accessible with the subscription?',\n",
       " 'What are assessments? How can I access them?',\n",
       " 'Where will I get the answers to the assessments?',\n",
       " 'Does the course contain any text content?',\n",
       " 'How can I access the text content?',\n",
       " 'What is an Integrated Course?',\n",
       " 'If I complete a course, will I get any certification?',\n",
       " 'How do I download a Video course?',\n",
       " 'Is \"Readium\" required to open certain blended courses?']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = [question.text.split(\"\\n\")[0].lstrip() for question in soup.find_all('div', attrs={\"class\": \"tab\"})]\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Once you complete your eBook purchase, the download link for your eBook will be available in your Packt account. You can access your eBook by following the steps below:\\n\\nLogin to your account\\nClick on \"My Account\"\\nClick on \"My owned products\"\\nDownload the eBook in your desired format.\\n\\nIf you own an eBook and are viewing the product page you can also download it from there\\nIf you have purchased an Early Access eBook?title you can only download the published chapters?from your account or read them online with an active subscription. You can download the complete eBook, only once the eBook is published.',\n",
       " 'Packt eBooks can be downloaded as a PDF, EPUB or MOBI file. They can also be viewed online using your subscription.',\n",
       " 'Yes, if you follow the previous instructions on how to download an eBook and select \"Send to Kindle\" you will be able to enter your Kindle details and send the file. There is however a 30MB limit on sending files to Kindle.',\n",
       " \"There are a number of simple ways to access Code Files. You can download them directly from the product page by clicking the 'Code Files' button just above the Book Description.\\nYou will also be able to download Code Files from inside your account. Go to 'My Account', click 'My eBooks', expand the product for which you wish to access the Code Files and then click on the 'Code Files' button. The download will start immediately.\\nIf you have purchased our eBook/Video from another source, please follow the steps below to download the code files:\\n \\n\\nRegister on our website using your email address and the password\\nGo to the ‘Support’ tab in the top horizontal drop down menu\\nClick on?‘Code Downloads & Errata’\\nType the name of the book in the search box\\nYour eBook/Video?should appear in a drop down – select the one you want\\nUse the drop down to tell us where you purchased the product from\\nFinally, click on the ‘Code Download link’ to download the Code Files\\n\\nOnce the file is downloaded please make sure that you unzip or extract using the latest version of:\\n\\nWinrar / 7zip for Windows\\nZipeg / iZip / Unrarx for Mac\\n7-zip / Peazip for Linux\\n\\nThe above mentioned applications support all extension files.\",\n",
       " 'Once you complete your Video purchase, the download link for your Video will be available in your Packt account. You can download your video by following the steps below:\\n \\n\\nLogin to your account\\nClick on \"My Account\"\\nClick on \"My owned products\"\\nClick?\"Video to download\"\\n\\nIf you own a Video and are viewing the product page you can also download it from there\\nMP4 is the only available format for Packt Videos.\\nIf you have purchased an Early Access video title you can only watch the sections that are published online if you have active subscription. You will have access to the complete Video, only once the Video is published.',\n",
       " \"There's no option to gift any of these. You can however create an account in your friend's name and make purchases using your credit card details. The eBook/Video/Course/Packt subscription will be available in your friend's account. You can however share an eBook with anyone if you have purchased more than one quantity of the same title. Simply click on share button and enter the Packt registered email id of the person you wish to share the eBook with.\",\n",
       " 'Yes, if you follow the previous instructions on how to download an eBook and select \"Send to Kindle\" you will be able to enter your Kindle details and send the file. There is however a 30MB limit on sending files to Kindle.',\n",
       " 'Integrated courses, Learning Path Courses and Curated courses.',\n",
       " 'None of the courses are accessible online. You will have to purchase the courses to access them.',\n",
       " 'Assessments are a learning validator to test the knowledge gained from the course. These assessments have multiple choice questions and are included in the \"Support Files\" folder. Please click on the Code Files button on the main product page to download the Support Files folder.',\n",
       " 'Assessment answers are in a PDF file that is available in the \"Support Files\" folder. Please click on the Code Files button on the main product page to download the Support Files folder.',\n",
       " 'The course is a blend of videos, text, code examples, and assessments.',\n",
       " 'The text content is available in the \"Support Files\" folder. Please click on the Code Files button on the main product page to download the Support Files folder.',\n",
       " 'An Integrated Course is a compilation of different eBooks and videos based on a topic to help you develop your skills on a specific technology.',\n",
       " 'Currently we do not provide certifications on completing any courses.',\n",
       " 'We recommend using Readium with the latest stable version of Google Chrome, or iBooks for OSX to read an EPUB file. This interactive EPUB adheres to the latest specification, and requires that your reader supports video and interactive content.',\n",
       " 'Yes, Readium is required to open a blended course. As a blended course is a combination of eBook and video, Readium is the best application to access the complete content without any hassle. Blended courses are only available in EPUB format and to open it, you need Readium with the latest stable version of Google Chrome, or iBooks for OSX.']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = [answer.text.strip() for answer in soup.find_all('div',attrs={\"class\":\"tab-content\"})]\n",
    "answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create a DataFrame consisting of questions and answers</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I download eBooks?</td>\n",
       "      <td>Once you complete your eBook purchase, the dow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What format are Packt eBooks?</td>\n",
       "      <td>Packt eBooks can be downloaded as a PDF, EPUB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I send an eBook to my Kindle?</td>\n",
       "      <td>Yes, if you follow the previous instructions o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I download code files for eBooks and V...</td>\n",
       "      <td>There are a number of simple ways to access Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I download Videos?</td>\n",
       "      <td>Once you complete your Video purchase, the dow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0                         How can I download eBooks?   \n",
       "1                      What format are Packt eBooks?   \n",
       "2                  Can I send an eBook to my Kindle?   \n",
       "3  How can I download code files for eBooks and V...   \n",
       "4                         How can I download Videos?   \n",
       "\n",
       "                                             answers  \n",
       "0  Once you complete your eBook purchase, the dow...  \n",
       "1  Packt eBooks can be downloaded as a PDF, EPUB ...  \n",
       "2  Yes, if you follow the previous instructions o...  \n",
       "3  There are a number of simple ways to access Co...  \n",
       "4  Once you complete your Video purchase, the dow...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'questions':questions, 'answers':answers}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fetch email addresses and phone numbers with the help of regular expressions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr_tc = http.request('GET', 'https://www.packtpub.com/books/info/packt/terms-and-conditions')\n",
    "rr_tc.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(rr_tc.data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customercare@packt.com', 'subscription.support@packt.com'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "set(re.findall(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}\",soup.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+44 (0) 121 265 648', '+44 (0) 121 212 141']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"\\+\\d{2}\\s{1}\\(0\\)\\s\\d{3}\\s\\d{3}\\s\\d{3}\",soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dealing with JSON Files</h2>\n",
    "<br>\n",
    "In this exercise, we will extract details such as the names of students, their qualifications, and additional qualifications from a JSON file. Follow these steps to implement this exercise.\n",
    "<br>\n",
    "<br>\n",
    "<b>Insert a new cell and import <code>json</code>. Pass the location of the file mentioned using the following commands</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'students': [{'name': 'Gangaram', 'qualification': 'B.Tech'},\n",
      "              {'name': 'Ganga', 'qualification': 'B.A.'},\n",
      "              {'additional qualification': 'M.Tech',\n",
      "               'name': 'Ram',\n",
      "               'qualification': 'B.Tech'},\n",
      "              {'name': 'Ramlal',\n",
      "               'other qualification': 'Diploma in Music',\n",
      "               'qualification': 'B.Music'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "data = json.load(open('data/sample_json.json'))\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To extract the names of the students, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gangaram', 'Ganga', 'Ram', 'Ramlal']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dt['name'] for dt in data['students']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To extract their qualifications, enter the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B.Tech', 'B.A.', 'B.Tech', 'B.Music']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dt['qualification'] for dt in data['students']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To extract their additional qualifications, enter the following code. Remember: not every student will have additional qualifications. Thus, we need to check this separately. Add the following code to implement this</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, 'M.Tech', None]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dt['additional qualification'] if 'additional qualification' in dt.keys() else None for dt in data['students']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, 'Diploma in Music']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[dt['other qualification'] if 'other qualification' in dt.keys() else None for dt in data['students']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dealing with Online Files</h2>\n",
    "<br>\n",
    "In this activity, we will fetch JSON files from online, extract comments, and evaluate the sentiment scores of each of them. We will make use of the TextBlob library. Follow these steps to implement this activity.\n",
    "<br>\n",
    "<br>\n",
    "Extract comments from <a href='https://jsonplaceholder.typicode.com/comments'>https://jsonplaceholder.typicode.com/comments</a> and evaluate sentiment scores of each of them using TextBlob and collect 15 author names and titles by parsing JSON files available from <a href='http://libgen.io/json.php'>http://libgen.io/json.php</a>\n",
    "<br>\n",
    "<br>\n",
    "<b>Import the necessary libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib3\n",
    "from textblob import TextBlob\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fetch the data from <a href='https://bit.ly/2TJ1T4H'>https://bit.ly/2TJ1T4H</a> the requests library</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "http = urllib3.PoolManager()\n",
    "rr = http.request('GET', 'https://jsonplaceholder.typicode.com/comments')\n",
    "rr.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(rr.data.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create a DataFrame from the fetched data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>id labore ex et quam laborum</td>\n",
       "      <td>Eliseo@gardner.biz</td>\n",
       "      <td>laudantium enim quasi est quidem magnam volupt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>quo vero reiciendis velit similique earum</td>\n",
       "      <td>Jayne_Kuhic@sydney.com</td>\n",
       "      <td>est natus enim nihil est dolore omnis voluptat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>odio adipisci rerum aut animi</td>\n",
       "      <td>Nikita@garfield.biz</td>\n",
       "      <td>quia molestiae reprehenderit quasi aspernatur\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>alias odio sit</td>\n",
       "      <td>Lew@alysha.tv</td>\n",
       "      <td>non et atque\\noccaecati deserunt quas accusant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>vero eaque aliquid doloribus et culpa</td>\n",
       "      <td>Hayden@althea.biz</td>\n",
       "      <td>harum non quasi et ratione\\ntempore iure ex vo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   postId  id                                       name  \\\n",
       "0       1   1               id labore ex et quam laborum   \n",
       "1       1   2  quo vero reiciendis velit similique earum   \n",
       "2       1   3              odio adipisci rerum aut animi   \n",
       "3       1   4                             alias odio sit   \n",
       "4       1   5      vero eaque aliquid doloribus et culpa   \n",
       "\n",
       "                    email                                               body  \n",
       "0      Eliseo@gardner.biz  laudantium enim quasi est quidem magnam volupt...  \n",
       "1  Jayne_Kuhic@sydney.com  est natus enim nihil est dolore omnis voluptat...  \n",
       "2     Nikita@garfield.biz  quia molestiae reprehenderit quasi aspernatur\\...  \n",
       "3           Lew@alysha.tv  non et atque\\noccaecati deserunt quas accusant...  \n",
       "4       Hayden@althea.biz  harum non quasi et ratione\\ntempore iure ex vo...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data).head(15)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Translate the comments in the data into English</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_english'] = df['body'].apply(lambda x: str(TextBlob('u'+str(x)).translate(to='en')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>body_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>laudantium enim quasi est quidem magnam volupt...</td>\n",
       "      <td>For them, as it were, is, indeed, the very gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>est natus enim nihil est dolore omnis voluptat...</td>\n",
       "      <td>uest was born, all the pain, the pleasure is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quia molestiae reprehenderit quasi aspernatur\\...</td>\n",
       "      <td>Uquia discomfort criticized as dislikes\\nof pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non et atque\\noccaecati deserunt quas accusant...</td>\n",
       "      <td>unon and and the\\nof denouncing pleasure and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>harum non quasi et ratione\\ntempore iure ex vo...</td>\n",
       "      <td>not as it were, and by reason of uhari\\nat the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  laudantium enim quasi est quidem magnam volupt...   \n",
       "1  est natus enim nihil est dolore omnis voluptat...   \n",
       "2  quia molestiae reprehenderit quasi aspernatur\\...   \n",
       "3  non et atque\\noccaecati deserunt quas accusant...   \n",
       "4  harum non quasi et ratione\\ntempore iure ex vo...   \n",
       "\n",
       "                                        body_english  \n",
       "0  For them, as it were, is, indeed, the very gre...  \n",
       "1  uest was born, all the pain, the pleasure is n...  \n",
       "2  Uquia discomfort criticized as dislikes\\nof pr...  \n",
       "3  unon and and the\\nof denouncing pleasure and f...  \n",
       "4  not as it were, and by reason of uhari\\nat the...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['body', 'body_english']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Make use of the TextBlob library to find the sentiment of each comment and display it</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_english</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For them, as it were, is, indeed, the very gre...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uest was born, all the pain, the pleasure is n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uquia discomfort criticized as dislikes\\nof pr...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unon and and the\\nof denouncing pleasure and f...</td>\n",
       "      <td>-0.4166666666666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not as it were, and by reason of uhari\\nat the...</td>\n",
       "      <td>0.32023809523809527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Udolorem at fault, but one which must be aband...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>but in labor and in pain, and in the same, and...</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>he wishes to become corrupt in the pleasure of...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>discomfort, and at once take usapiente\\nso tha...</td>\n",
       "      <td>-0.33888888888888885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uvoluptate regular very important for us to fi...</td>\n",
       "      <td>0.31777777777777777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>our sorrows, is that because it is either uût\\...</td>\n",
       "      <td>0.35555555555555557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>uexpedita greater deserving easy\\ndesires to f...</td>\n",
       "      <td>0.12666666666666668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ufugit them only was this grief of things,\\nfi...</td>\n",
       "      <td>-0.07500000000000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the exercise of which is the pleasure of those...</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the flattery of her, but I hated to think of p...</td>\n",
       "      <td>-0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         body_english       sentiment_score\n",
       "0   For them, as it were, is, indeed, the very gre...                   1.0\n",
       "1   uest was born, all the pain, the pleasure is n...                   0.0\n",
       "2   Uquia discomfort criticized as dislikes\\nof pr...                   0.5\n",
       "3   unon and and the\\nof denouncing pleasure and f...   -0.4166666666666667\n",
       "4   not as it were, and by reason of uhari\\nat the...   0.32023809523809527\n",
       "5   Udolorem at fault, but one which must be aband...                   0.0\n",
       "6   but in labor and in pain, and in the same, and...                   0.4\n",
       "7   he wishes to become corrupt in the pleasure of...                   0.0\n",
       "8   discomfort, and at once take usapiente\\nso tha...  -0.33888888888888885\n",
       "9   Uvoluptate regular very important for us to fi...   0.31777777777777777\n",
       "10  our sorrows, is that because it is either uût\\...   0.35555555555555557\n",
       "11  uexpedita greater deserving easy\\ndesires to f...   0.12666666666666668\n",
       "12  Ufugit them only was this grief of things,\\nfi...  -0.07500000000000001\n",
       "13  the exercise of which is the pleasure of those...                 0.275\n",
       "14  the flattery of her, but I hated to think of p...                  -0.9"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_score'] = df['body_english'].apply(lambda x: str(TextBlob('u'+str(x)).sentiment.polarity))\n",
    "df[['body_english', 'sentiment_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dealing with a Local XML File</h2>\n",
    "<br>\n",
    "In this exercise, we will parse an XML file and print various things, such as the names of employees, the organizations they work for, and the total salaries of all employees. Follow these steps to implement this exercise.\n",
    "<br>\n",
    "<br>\n",
    "<b>Insert a new cell, <code>import xml.etree.ElementTree</code>, and pass the location of the XML file using the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'records' at 0x0000024B854F3AE8>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('data/sample_xml_data.xml')\n",
    "root = tree.getroot()\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To check the tag of the fetched element, type the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'records'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Look for the <code>name</code> and <code>company</code> tags in the XML and print the data enclosed within them</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Peter Brewer  Company:  Erat Ltd  Salary:  $5,042\n",
      "Name:  Wallace Pace  Company:  Sed Nunc Industries  Salary:  $9,290\n",
      "Name:  Arthur Ray  Company:  Amet Faucibus Corp.  Salary:  $8,199\n",
      "Name:  Judah Vaughn  Company:  Nunc Quis Arcu Inc.  Salary:  $9,007\n",
      "Name:  Talon Combs  Company:  Leo Elementum Ltd  Salary:  $9,875\n",
      "Name:  Hall Bruce  Company:  Proin Non Massa Consulting  Salary:  $6,527\n",
      "Name:  Ronan Grant  Company:  Scelerisque Sed Inc.  Salary:  $5,507\n",
      "Name:  Dennis Whitaker  Company:  Scelerisque Neque Foundation  Salary:  $9,196\n",
      "Name:  Bradley Oconnor  Company:  Aliquet Corporation  Salary:  $9,069\n",
      "Name:  Forrest Alvarez  Company:  Et Eros Institute  Salary:  $6,012\n",
      "Name:  Ignatius Meyers  Company:  Facilisis Lorem Limited  Salary:  $9,588\n",
      "Name:  Bert Randolph  Company:  Facilisis LLP  Salary:  $9,862\n",
      "Name:  Victor Stevenson  Company:  Lacinia Vitae Sodales Incorporated  Salary:  $5,885\n",
      "Name:  Jamal Cummings  Company:  Litora Ltd  Salary:  $6,296\n",
      "Name:  Samson Estrada  Company:  Lacinia Vitae Sodales Industries  Salary:  $9,922\n",
      "Name:  Ira Spencer  Company:  Duis Associates  Salary:  $8,007\n",
      "Name:  Kevin Henson  Company:  Sagittis Limited  Salary:  $9,088\n",
      "Name:  Melvin Mccarthy  Company:  Ipsum Suspendisse Company  Salary:  $7,229\n",
      "Name:  Kieran Underwood  Company:  Quisque Porttitor Eros Ltd  Salary:  $8,913\n",
      "Name:  Cedric Phelps  Company:  Lorem Vehicula Corp.  Salary:  $7,855\n"
     ]
    }
   ],
   "source": [
    "for record in root.findall('record')[:20]:\n",
    "    print(\"Name: \", record.find('name').text, \" Company: \", record.find('company').text, \" Salary: \", record.find('salary').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Create a list consisting of the salaries of all employees. Use numpy to find out the sum of the salaries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745609"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum([int(record.find('salary').text.replace('$', '').replace(',','')) for record in root.findall('record')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Collecting Data Using APIs</h2>\n",
    "<br>\n",
    "In this exercise, we will extract carbon intensities from December 30, 2018, to January 3, 2019, using an API. Follow these steps to implement this exercise.\n",
    "<br>\n",
    "<br>\n",
    "<b>Import the necessary packages</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Construct the corresponding URL and call it</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "start_dt = '2018-12-30T12:35Z'\n",
    "end_dt = '2019-01-03T12:35Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kleye\\anaconda3\\envs\\ai\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rrq = http.request('GET', 'https://api.carbonintensity.org.uk/intensity/'+start_dt+'/'+end_dt, \\\n",
    "                   headers = {'Accept': 'application/json'})\n",
    "rrq.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load the json data, insert a new cell, and add the following code to implement this</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'from': '2018-12-30T12:30Z',\n",
      "           'intensity': {'actual': 203, 'forecast': 202, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T13:00Z'},\n",
      "          {'from': '2018-12-30T13:00Z',\n",
      "           'intensity': {'actual': 208, 'forecast': 201, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T13:30Z'},\n",
      "          {'from': '2018-12-30T13:30Z',\n",
      "           'intensity': {'actual': 217, 'forecast': 205, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T14:00Z'},\n",
      "          {'from': '2018-12-30T14:00Z',\n",
      "           'intensity': {'actual': 225, 'forecast': 214, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T14:30Z'},\n",
      "          {'from': '2018-12-30T14:30Z',\n",
      "           'intensity': {'actual': 235, 'forecast': 220, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T15:00Z'},\n",
      "          {'from': '2018-12-30T15:00Z',\n",
      "           'intensity': {'actual': 247, 'forecast': 231, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T15:30Z'},\n",
      "          {'from': '2018-12-30T15:30Z',\n",
      "           'intensity': {'actual': 265, 'forecast': 242, 'index': 'high'},\n",
      "           'to': '2018-12-30T16:00Z'},\n",
      "          {'from': '2018-12-30T16:00Z',\n",
      "           'intensity': {'actual': 275, 'forecast': 257, 'index': 'high'},\n",
      "           'to': '2018-12-30T16:30Z'},\n",
      "          {'from': '2018-12-30T16:30Z',\n",
      "           'intensity': {'actual': 273, 'forecast': 275, 'index': 'high'},\n",
      "           'to': '2018-12-30T17:00Z'},\n",
      "          {'from': '2018-12-30T17:00Z',\n",
      "           'intensity': {'actual': 268, 'forecast': 281, 'index': 'high'},\n",
      "           'to': '2018-12-30T17:30Z'},\n",
      "          {'from': '2018-12-30T17:30Z',\n",
      "           'intensity': {'actual': 267, 'forecast': 279, 'index': 'high'},\n",
      "           'to': '2018-12-30T18:00Z'},\n",
      "          {'from': '2018-12-30T18:00Z',\n",
      "           'intensity': {'actual': 268, 'forecast': 271, 'index': 'high'},\n",
      "           'to': '2018-12-30T18:30Z'},\n",
      "          {'from': '2018-12-30T18:30Z',\n",
      "           'intensity': {'actual': 264, 'forecast': 267, 'index': 'high'},\n",
      "           'to': '2018-12-30T19:00Z'},\n",
      "          {'from': '2018-12-30T19:00Z',\n",
      "           'intensity': {'actual': 259, 'forecast': 266, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T19:30Z'},\n",
      "          {'from': '2018-12-30T19:30Z',\n",
      "           'intensity': {'actual': 245, 'forecast': 261, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T20:00Z'},\n",
      "          {'from': '2018-12-30T20:00Z',\n",
      "           'intensity': {'actual': 231, 'forecast': 255, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T20:30Z'},\n",
      "          {'from': '2018-12-30T20:30Z',\n",
      "           'intensity': {'actual': 218, 'forecast': 237, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T21:00Z'},\n",
      "          {'from': '2018-12-30T21:00Z',\n",
      "           'intensity': {'actual': 207, 'forecast': 225, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T21:30Z'},\n",
      "          {'from': '2018-12-30T21:30Z',\n",
      "           'intensity': {'actual': 201, 'forecast': 216, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T22:00Z'},\n",
      "          {'from': '2018-12-30T22:00Z',\n",
      "           'intensity': {'actual': 194, 'forecast': 207, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T22:30Z'},\n",
      "          {'from': '2018-12-30T22:30Z',\n",
      "           'intensity': {'actual': 183, 'forecast': 199, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T23:00Z'},\n",
      "          {'from': '2018-12-30T23:00Z',\n",
      "           'intensity': {'actual': 171, 'forecast': 191, 'index': 'moderate'},\n",
      "           'to': '2018-12-30T23:30Z'},\n",
      "          {'from': '2018-12-30T23:30Z',\n",
      "           'intensity': {'actual': 167, 'forecast': 181, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T00:00Z'},\n",
      "          {'from': '2018-12-31T00:00Z',\n",
      "           'intensity': {'actual': 157, 'forecast': 168, 'index': 'low'},\n",
      "           'to': '2018-12-31T00:30Z'},\n",
      "          {'from': '2018-12-31T00:30Z',\n",
      "           'intensity': {'actual': 159, 'forecast': 157, 'index': 'low'},\n",
      "           'to': '2018-12-31T01:00Z'},\n",
      "          {'from': '2018-12-31T01:00Z',\n",
      "           'intensity': {'actual': 160, 'forecast': 159, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T01:30Z'},\n",
      "          {'from': '2018-12-31T01:30Z',\n",
      "           'intensity': {'actual': 161, 'forecast': 161, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T02:00Z'},\n",
      "          {'from': '2018-12-31T02:00Z',\n",
      "           'intensity': {'actual': 167, 'forecast': 160, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T02:30Z'},\n",
      "          {'from': '2018-12-31T02:30Z',\n",
      "           'intensity': {'actual': 165, 'forecast': 166, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T03:00Z'},\n",
      "          {'from': '2018-12-31T03:00Z',\n",
      "           'intensity': {'actual': 157, 'forecast': 172, 'index': 'low'},\n",
      "           'to': '2018-12-31T03:30Z'},\n",
      "          {'from': '2018-12-31T03:30Z',\n",
      "           'intensity': {'actual': 150, 'forecast': 162, 'index': 'low'},\n",
      "           'to': '2018-12-31T04:00Z'},\n",
      "          {'from': '2018-12-31T04:00Z',\n",
      "           'intensity': {'actual': 152, 'forecast': 155, 'index': 'low'},\n",
      "           'to': '2018-12-31T04:30Z'},\n",
      "          {'from': '2018-12-31T04:30Z',\n",
      "           'intensity': {'actual': 155, 'forecast': 149, 'index': 'low'},\n",
      "           'to': '2018-12-31T05:00Z'},\n",
      "          {'from': '2018-12-31T05:00Z',\n",
      "           'intensity': {'actual': 158, 'forecast': 155, 'index': 'low'},\n",
      "           'to': '2018-12-31T05:30Z'},\n",
      "          {'from': '2018-12-31T05:30Z',\n",
      "           'intensity': {'actual': 170, 'forecast': 159, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T06:00Z'},\n",
      "          {'from': '2018-12-31T06:00Z',\n",
      "           'intensity': {'actual': 181, 'forecast': 165, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T06:30Z'},\n",
      "          {'from': '2018-12-31T06:30Z',\n",
      "           'intensity': {'actual': 190, 'forecast': 178, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T07:00Z'},\n",
      "          {'from': '2018-12-31T07:00Z',\n",
      "           'intensity': {'actual': 189, 'forecast': 190, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T07:30Z'},\n",
      "          {'from': '2018-12-31T07:30Z',\n",
      "           'intensity': {'actual': 190, 'forecast': 194, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T08:00Z'},\n",
      "          {'from': '2018-12-31T08:00Z',\n",
      "           'intensity': {'actual': 201, 'forecast': 191, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T08:30Z'},\n",
      "          {'from': '2018-12-31T08:30Z',\n",
      "           'intensity': {'actual': 213, 'forecast': 189, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T09:00Z'},\n",
      "          {'from': '2018-12-31T09:00Z',\n",
      "           'intensity': {'actual': 219, 'forecast': 206, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T09:30Z'},\n",
      "          {'from': '2018-12-31T09:30Z',\n",
      "           'intensity': {'actual': 221, 'forecast': 215, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T10:00Z'},\n",
      "          {'from': '2018-12-31T10:00Z',\n",
      "           'intensity': {'actual': 226, 'forecast': 223, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T10:30Z'},\n",
      "          {'from': '2018-12-31T10:30Z',\n",
      "           'intensity': {'actual': 226, 'forecast': 225, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T11:00Z'},\n",
      "          {'from': '2018-12-31T11:00Z',\n",
      "           'intensity': {'actual': 224, 'forecast': 231, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T11:30Z'},\n",
      "          {'from': '2018-12-31T11:30Z',\n",
      "           'intensity': {'actual': 225, 'forecast': 225, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T12:00Z'},\n",
      "          {'from': '2018-12-31T12:00Z',\n",
      "           'intensity': {'actual': 223, 'forecast': 218, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T12:30Z'},\n",
      "          {'from': '2018-12-31T12:30Z',\n",
      "           'intensity': {'actual': 227, 'forecast': 219, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T13:00Z'},\n",
      "          {'from': '2018-12-31T13:00Z',\n",
      "           'intensity': {'actual': 228, 'forecast': 221, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T13:30Z'},\n",
      "          {'from': '2018-12-31T13:30Z',\n",
      "           'intensity': {'actual': 222, 'forecast': 228, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T14:00Z'},\n",
      "          {'from': '2018-12-31T14:00Z',\n",
      "           'intensity': {'actual': 223, 'forecast': 224, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T14:30Z'},\n",
      "          {'from': '2018-12-31T14:30Z',\n",
      "           'intensity': {'actual': 222, 'forecast': 218, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T15:00Z'},\n",
      "          {'from': '2018-12-31T15:00Z',\n",
      "           'intensity': {'actual': 224, 'forecast': 219, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T15:30Z'},\n",
      "          {'from': '2018-12-31T15:30Z',\n",
      "           'intensity': {'actual': 228, 'forecast': 218, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T16:00Z'},\n",
      "          {'from': '2018-12-31T16:00Z',\n",
      "           'intensity': {'actual': 235, 'forecast': 224, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T16:30Z'},\n",
      "          {'from': '2018-12-31T16:30Z',\n",
      "           'intensity': {'actual': 235, 'forecast': 231, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T17:00Z'},\n",
      "          {'from': '2018-12-31T17:00Z',\n",
      "           'intensity': {'actual': 233, 'forecast': 237, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T17:30Z'},\n",
      "          {'from': '2018-12-31T17:30Z',\n",
      "           'intensity': {'actual': 227, 'forecast': 241, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T18:00Z'},\n",
      "          {'from': '2018-12-31T18:00Z',\n",
      "           'intensity': {'actual': 218, 'forecast': 232, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T18:30Z'},\n",
      "          {'from': '2018-12-31T18:30Z',\n",
      "           'intensity': {'actual': 208, 'forecast': 225, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T19:00Z'},\n",
      "          {'from': '2018-12-31T19:00Z',\n",
      "           'intensity': {'actual': 197, 'forecast': 211, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T19:30Z'},\n",
      "          {'from': '2018-12-31T19:30Z',\n",
      "           'intensity': {'actual': 185, 'forecast': 201, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T20:00Z'},\n",
      "          {'from': '2018-12-31T20:00Z',\n",
      "           'intensity': {'actual': 166, 'forecast': 188, 'index': 'moderate'},\n",
      "           'to': '2018-12-31T20:30Z'},\n",
      "          {'from': '2018-12-31T20:30Z',\n",
      "           'intensity': {'actual': 152, 'forecast': 175, 'index': 'low'},\n",
      "           'to': '2018-12-31T21:00Z'},\n",
      "          {'from': '2018-12-31T21:00Z',\n",
      "           'intensity': {'actual': 143, 'forecast': 156, 'index': 'low'},\n",
      "           'to': '2018-12-31T21:30Z'},\n",
      "          {'from': '2018-12-31T21:30Z',\n",
      "           'intensity': {'actual': 136, 'forecast': 147, 'index': 'low'},\n",
      "           'to': '2018-12-31T22:00Z'},\n",
      "          {'from': '2018-12-31T22:00Z',\n",
      "           'intensity': {'actual': 134, 'forecast': 136, 'index': 'low'},\n",
      "           'to': '2018-12-31T22:30Z'},\n",
      "          {'from': '2018-12-31T22:30Z',\n",
      "           'intensity': {'actual': 122, 'forecast': 134, 'index': 'low'},\n",
      "           'to': '2018-12-31T23:00Z'},\n",
      "          {'from': '2018-12-31T23:00Z',\n",
      "           'intensity': {'actual': 114, 'forecast': 130, 'index': 'low'},\n",
      "           'to': '2018-12-31T23:30Z'},\n",
      "          {'from': '2018-12-31T23:30Z',\n",
      "           'intensity': {'actual': 112, 'forecast': 116, 'index': 'low'},\n",
      "           'to': '2019-01-01T00:00Z'},\n",
      "          {'from': '2019-01-01T00:00Z',\n",
      "           'intensity': {'actual': 111, 'forecast': 113, 'index': 'low'},\n",
      "           'to': '2019-01-01T00:30Z'},\n",
      "          {'from': '2019-01-01T00:30Z',\n",
      "           'intensity': {'actual': 114, 'forecast': 106, 'index': 'low'},\n",
      "           'to': '2019-01-01T01:00Z'},\n",
      "          {'from': '2019-01-01T01:00Z',\n",
      "           'intensity': {'actual': 107, 'forecast': 115, 'index': 'low'},\n",
      "           'to': '2019-01-01T01:30Z'},\n",
      "          {'from': '2019-01-01T01:30Z',\n",
      "           'intensity': {'actual': 107, 'forecast': 116, 'index': 'low'},\n",
      "           'to': '2019-01-01T02:00Z'},\n",
      "          {'from': '2019-01-01T02:00Z',\n",
      "           'intensity': {'actual': 114, 'forecast': 107, 'index': 'low'},\n",
      "           'to': '2019-01-01T02:30Z'},\n",
      "          {'from': '2019-01-01T02:30Z',\n",
      "           'intensity': {'actual': 112, 'forecast': 111, 'index': 'low'},\n",
      "           'to': '2019-01-01T03:00Z'},\n",
      "          {'from': '2019-01-01T03:00Z',\n",
      "           'intensity': {'actual': 108, 'forecast': 117, 'index': 'low'},\n",
      "           'to': '2019-01-01T03:30Z'},\n",
      "          {'from': '2019-01-01T03:30Z',\n",
      "           'intensity': {'actual': 109, 'forecast': 117, 'index': 'low'},\n",
      "           'to': '2019-01-01T04:00Z'},\n",
      "          {'from': '2019-01-01T04:00Z',\n",
      "           'intensity': {'actual': 112, 'forecast': 110, 'index': 'low'},\n",
      "           'to': '2019-01-01T04:30Z'},\n",
      "          {'from': '2019-01-01T04:30Z',\n",
      "           'intensity': {'actual': 116, 'forecast': 114, 'index': 'low'},\n",
      "           'to': '2019-01-01T05:00Z'},\n",
      "          {'from': '2019-01-01T05:00Z',\n",
      "           'intensity': {'actual': 123, 'forecast': 118, 'index': 'low'},\n",
      "           'to': '2019-01-01T05:30Z'},\n",
      "          {'from': '2019-01-01T05:30Z',\n",
      "           'intensity': {'actual': 131, 'forecast': 123, 'index': 'low'},\n",
      "           'to': '2019-01-01T06:00Z'},\n",
      "          {'from': '2019-01-01T06:00Z',\n",
      "           'intensity': {'actual': 138, 'forecast': 132, 'index': 'low'},\n",
      "           'to': '2019-01-01T06:30Z'},\n",
      "          {'from': '2019-01-01T06:30Z',\n",
      "           'intensity': {'actual': 133, 'forecast': 139, 'index': 'low'},\n",
      "           'to': '2019-01-01T07:00Z'},\n",
      "          {'from': '2019-01-01T07:00Z',\n",
      "           'intensity': {'actual': 127, 'forecast': 143, 'index': 'low'},\n",
      "           'to': '2019-01-01T07:30Z'},\n",
      "          {'from': '2019-01-01T07:30Z',\n",
      "           'intensity': {'actual': 136, 'forecast': 129, 'index': 'low'},\n",
      "           'to': '2019-01-01T08:00Z'},\n",
      "          {'from': '2019-01-01T08:00Z',\n",
      "           'intensity': {'actual': 150, 'forecast': 129, 'index': 'low'},\n",
      "           'to': '2019-01-01T08:30Z'},\n",
      "          {'from': '2019-01-01T08:30Z',\n",
      "           'intensity': {'actual': 169, 'forecast': 139, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T09:00Z'},\n",
      "          {'from': '2019-01-01T09:00Z',\n",
      "           'intensity': {'actual': 183, 'forecast': 157, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T09:30Z'},\n",
      "          {'from': '2019-01-01T09:30Z',\n",
      "           'intensity': {'actual': 188, 'forecast': 181, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T10:00Z'},\n",
      "          {'from': '2019-01-01T10:00Z',\n",
      "           'intensity': {'actual': 194, 'forecast': 193, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T10:30Z'},\n",
      "          {'from': '2019-01-01T10:30Z',\n",
      "           'intensity': {'actual': 205, 'forecast': 195, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T11:00Z'},\n",
      "          {'from': '2019-01-01T11:00Z',\n",
      "           'intensity': {'actual': 208, 'forecast': 200, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T11:30Z'},\n",
      "          {'from': '2019-01-01T11:30Z',\n",
      "           'intensity': {'actual': 211, 'forecast': 208, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T12:00Z'},\n",
      "          {'from': '2019-01-01T12:00Z',\n",
      "           'intensity': {'actual': 216, 'forecast': 209, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T12:30Z'},\n",
      "          {'from': '2019-01-01T12:30Z',\n",
      "           'intensity': {'actual': 226, 'forecast': 208, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T13:00Z'},\n",
      "          {'from': '2019-01-01T13:00Z',\n",
      "           'intensity': {'actual': 231, 'forecast': 218, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T13:30Z'},\n",
      "          {'from': '2019-01-01T13:30Z',\n",
      "           'intensity': {'actual': 233, 'forecast': 228, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T14:00Z'},\n",
      "          {'from': '2019-01-01T14:00Z',\n",
      "           'intensity': {'actual': 241, 'forecast': 232, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T14:30Z'},\n",
      "          {'from': '2019-01-01T14:30Z',\n",
      "           'intensity': {'actual': 248, 'forecast': 236, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T15:00Z'},\n",
      "          {'from': '2019-01-01T15:00Z',\n",
      "           'intensity': {'actual': 258, 'forecast': 247, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T15:30Z'},\n",
      "          {'from': '2019-01-01T15:30Z',\n",
      "           'intensity': {'actual': 279, 'forecast': 251, 'index': 'high'},\n",
      "           'to': '2019-01-01T16:00Z'},\n",
      "          {'from': '2019-01-01T16:00Z',\n",
      "           'intensity': {'actual': 295, 'forecast': 263, 'index': 'high'},\n",
      "           'to': '2019-01-01T16:30Z'},\n",
      "          {'from': '2019-01-01T16:30Z',\n",
      "           'intensity': {'actual': 294, 'forecast': 292, 'index': 'high'},\n",
      "           'to': '2019-01-01T17:00Z'},\n",
      "          {'from': '2019-01-01T17:00Z',\n",
      "           'intensity': {'actual': 295, 'forecast': 304, 'index': 'high'},\n",
      "           'to': '2019-01-01T17:30Z'},\n",
      "          {'from': '2019-01-01T17:30Z',\n",
      "           'intensity': {'actual': 296, 'forecast': 298, 'index': 'high'},\n",
      "           'to': '2019-01-01T18:00Z'},\n",
      "          {'from': '2019-01-01T18:00Z',\n",
      "           'intensity': {'actual': 299, 'forecast': 302, 'index': 'high'},\n",
      "           'to': '2019-01-01T18:30Z'},\n",
      "          {'from': '2019-01-01T18:30Z',\n",
      "           'intensity': {'actual': 292, 'forecast': 299, 'index': 'high'},\n",
      "           'to': '2019-01-01T19:00Z'},\n",
      "          {'from': '2019-01-01T19:00Z',\n",
      "           'intensity': {'actual': 278, 'forecast': 294, 'index': 'high'},\n",
      "           'to': '2019-01-01T19:30Z'},\n",
      "          {'from': '2019-01-01T19:30Z',\n",
      "           'intensity': {'actual': 275, 'forecast': 282, 'index': 'high'},\n",
      "           'to': '2019-01-01T20:00Z'},\n",
      "          {'from': '2019-01-01T20:00Z',\n",
      "           'intensity': {'actual': 268, 'forecast': 272, 'index': 'high'},\n",
      "           'to': '2019-01-01T20:30Z'},\n",
      "          {'from': '2019-01-01T20:30Z',\n",
      "           'intensity': {'actual': 262, 'forecast': 270, 'index': 'high'},\n",
      "           'to': '2019-01-01T21:00Z'},\n",
      "          {'from': '2019-01-01T21:00Z',\n",
      "           'intensity': {'actual': 254, 'forecast': 263, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T21:30Z'},\n",
      "          {'from': '2019-01-01T21:30Z',\n",
      "           'intensity': {'actual': 256, 'forecast': 258, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T22:00Z'},\n",
      "          {'from': '2019-01-01T22:00Z',\n",
      "           'intensity': {'actual': 259, 'forecast': 250, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T22:30Z'},\n",
      "          {'from': '2019-01-01T22:30Z',\n",
      "           'intensity': {'actual': 249, 'forecast': 258, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T23:00Z'},\n",
      "          {'from': '2019-01-01T23:00Z',\n",
      "           'intensity': {'actual': 238, 'forecast': 256, 'index': 'moderate'},\n",
      "           'to': '2019-01-01T23:30Z'},\n",
      "          {'from': '2019-01-01T23:30Z',\n",
      "           'intensity': {'actual': 238, 'forecast': 243, 'index': 'moderate'},\n",
      "           'to': '2019-01-02T00:00Z'},\n",
      "          {'from': '2019-01-02T00:00Z',\n",
      "           'intensity': {'actual': 242, 'forecast': 239, 'index': 'moderate'},\n",
      "           'to': '2019-01-02T00:30Z'},\n",
      "          {'from': '2019-01-02T00:30Z',\n",
      "           'intensity': {'actual': 249, 'forecast': 235, 'index': 'moderate'},\n",
      "           'to': '2019-01-02T01:00Z'},\n",
      "          {'from': '2019-01-02T01:00Z',\n",
      "           'intensity': {'actual': 251, 'forecast': 248, 'index': 'moderate'},\n",
      "           'to': '2019-01-02T01:30Z'},\n",
      "          {'from': '2019-01-02T01:30Z',\n",
      "           'intensity': {'actual': 257, 'forecast': 257, 'index': 'moderate'},\n",
      "           'to': '2019-01-02T02:00Z'},\n",
      "          {'from': '2019-01-02T02:00Z',\n",
      "           'intensity': {'actual': 260, 'forecast': 256, 'index': 'high'},\n",
      "           'to': '2019-01-02T02:30Z'},\n",
      "          {'from': '2019-01-02T02:30Z',\n",
      "           'intensity': {'actual': 261, 'forecast': 258, 'index': 'high'},\n",
      "           'to': '2019-01-02T03:00Z'},\n",
      "          {'from': '2019-01-02T03:00Z',\n",
      "           'intensity': {'actual': 263, 'forecast': 261, 'index': 'high'},\n",
      "           'to': '2019-01-02T03:30Z'},\n",
      "          {'from': '2019-01-02T03:30Z',\n",
      "           'intensity': {'actual': 258, 'forecast': 264, 'index': 'moderate'},\n",
      "           'to': '2019-01-02T04:00Z'},\n",
      "          {'from': '2019-01-02T04:00Z',\n",
      "           'intensity': {'actual': 264, 'forecast': 266, 'index': 'high'},\n",
      "           'to': '2019-01-02T04:30Z'},\n",
      "          {'from': '2019-01-02T04:30Z',\n",
      "           'intensity': {'actual': 264, 'forecast': 260, 'index': 'high'},\n",
      "           'to': '2019-01-02T05:00Z'},\n",
      "          {'from': '2019-01-02T05:00Z',\n",
      "           'intensity': {'actual': 272, 'forecast': 264, 'index': 'high'},\n",
      "           'to': '2019-01-02T05:30Z'},\n",
      "          {'from': '2019-01-02T05:30Z',\n",
      "           'intensity': {'actual': 282, 'forecast': 270, 'index': 'high'},\n",
      "           'to': '2019-01-02T06:00Z'},\n",
      "          {'from': '2019-01-02T06:00Z',\n",
      "           'intensity': {'actual': 296, 'forecast': 279, 'index': 'high'},\n",
      "           'to': '2019-01-02T06:30Z'},\n",
      "          {'from': '2019-01-02T06:30Z',\n",
      "           'intensity': {'actual': 319, 'forecast': 283, 'index': 'high'},\n",
      "           'to': '2019-01-02T07:00Z'},\n",
      "          {'from': '2019-01-02T07:00Z',\n",
      "           'intensity': {'actual': 334, 'forecast': 309, 'index': 'high'},\n",
      "           'to': '2019-01-02T07:30Z'},\n",
      "          {'from': '2019-01-02T07:30Z',\n",
      "           'intensity': {'actual': 330, 'forecast': 344, 'index': 'high'},\n",
      "           'to': '2019-01-02T08:00Z'},\n",
      "          {'from': '2019-01-02T08:00Z',\n",
      "           'intensity': {'actual': 327, 'forecast': 344, 'index': 'high'},\n",
      "           'to': '2019-01-02T08:30Z'},\n",
      "          {'from': '2019-01-02T08:30Z',\n",
      "           'intensity': {'actual': 331, 'forecast': 324, 'index': 'high'},\n",
      "           'to': '2019-01-02T09:00Z'},\n",
      "          {'from': '2019-01-02T09:00Z',\n",
      "           'intensity': {'actual': 338, 'forecast': 320, 'index': 'high'},\n",
      "           'to': '2019-01-02T09:30Z'},\n",
      "          {'from': '2019-01-02T09:30Z',\n",
      "           'intensity': {'actual': 342, 'forecast': 326, 'index': 'high'},\n",
      "           'to': '2019-01-02T10:00Z'},\n",
      "          {'from': '2019-01-02T10:00Z',\n",
      "           'intensity': {'actual': 342, 'forecast': 338, 'index': 'high'},\n",
      "           'to': '2019-01-02T10:30Z'},\n",
      "          {'from': '2019-01-02T10:30Z',\n",
      "           'intensity': {'actual': 341, 'forecast': 341, 'index': 'high'},\n",
      "           'to': '2019-01-02T11:00Z'},\n",
      "          {'from': '2019-01-02T11:00Z',\n",
      "           'intensity': {'actual': 342, 'forecast': 338, 'index': 'high'},\n",
      "           'to': '2019-01-02T11:30Z'},\n",
      "          {'from': '2019-01-02T11:30Z',\n",
      "           'intensity': {'actual': 343, 'forecast': 336, 'index': 'high'},\n",
      "           'to': '2019-01-02T12:00Z'},\n",
      "          {'from': '2019-01-02T12:00Z',\n",
      "           'intensity': {'actual': 346, 'forecast': 340, 'index': 'high'},\n",
      "           'to': '2019-01-02T12:30Z'},\n",
      "          {'from': '2019-01-02T12:30Z',\n",
      "           'intensity': {'actual': 352, 'forecast': 342, 'index': 'high'},\n",
      "           'to': '2019-01-02T13:00Z'},\n",
      "          {'from': '2019-01-02T13:00Z',\n",
      "           'intensity': {'actual': 355, 'forecast': 347, 'index': 'high'},\n",
      "           'to': '2019-01-02T13:30Z'},\n",
      "          {'from': '2019-01-02T13:30Z',\n",
      "           'intensity': {'actual': 360, 'forecast': 351, 'index': 'very high'},\n",
      "           'to': '2019-01-02T14:00Z'},\n",
      "          {'from': '2019-01-02T14:00Z',\n",
      "           'intensity': {'actual': 371, 'forecast': 354, 'index': 'very high'},\n",
      "           'to': '2019-01-02T14:30Z'},\n",
      "          {'from': '2019-01-02T14:30Z',\n",
      "           'intensity': {'actual': 378, 'forecast': 363, 'index': 'very high'},\n",
      "           'to': '2019-01-02T15:00Z'},\n",
      "          {'from': '2019-01-02T15:00Z',\n",
      "           'intensity': {'actual': 380, 'forecast': 377, 'index': 'very high'},\n",
      "           'to': '2019-01-02T15:30Z'},\n",
      "          {'from': '2019-01-02T15:30Z',\n",
      "           'intensity': {'actual': 384, 'forecast': 380, 'index': 'very high'},\n",
      "           'to': '2019-01-02T16:00Z'},\n",
      "          {'from': '2019-01-02T16:00Z',\n",
      "           'intensity': {'actual': 388, 'forecast': 385, 'index': 'very high'},\n",
      "           'to': '2019-01-02T16:30Z'},\n",
      "          {'from': '2019-01-02T16:30Z',\n",
      "           'intensity': {'actual': 385, 'forecast': 390, 'index': 'very high'},\n",
      "           'to': '2019-01-02T17:00Z'},\n",
      "          {'from': '2019-01-02T17:00Z',\n",
      "           'intensity': {'actual': 379, 'forecast': 392, 'index': 'very high'},\n",
      "           'to': '2019-01-02T17:30Z'},\n",
      "          {'from': '2019-01-02T17:30Z',\n",
      "           'intensity': {'actual': 377, 'forecast': 388, 'index': 'very high'},\n",
      "           'to': '2019-01-02T18:00Z'},\n",
      "          {'from': '2019-01-02T18:00Z',\n",
      "           'intensity': {'actual': 378, 'forecast': 374, 'index': 'very high'},\n",
      "           'to': '2019-01-02T18:30Z'},\n",
      "          {'from': '2019-01-02T18:30Z',\n",
      "           'intensity': {'actual': 383, 'forecast': 369, 'index': 'very high'},\n",
      "           'to': '2019-01-02T19:00Z'},\n",
      "          {'from': '2019-01-02T19:00Z',\n",
      "           'intensity': {'actual': 390, 'forecast': 374, 'index': 'very high'},\n",
      "           'to': '2019-01-02T19:30Z'},\n",
      "          {'from': '2019-01-02T19:30Z',\n",
      "           'intensity': {'actual': 394, 'forecast': 385, 'index': 'very high'},\n",
      "           'to': '2019-01-02T20:00Z'},\n",
      "          {'from': '2019-01-02T20:00Z',\n",
      "           'intensity': {'actual': 392, 'forecast': 395, 'index': 'very high'},\n",
      "           'to': '2019-01-02T20:30Z'},\n",
      "          {'from': '2019-01-02T20:30Z',\n",
      "           'intensity': {'actual': 379, 'forecast': 398, 'index': 'very high'},\n",
      "           'to': '2019-01-02T21:00Z'},\n",
      "          {'from': '2019-01-02T21:00Z',\n",
      "           'intensity': {'actual': 359, 'forecast': 392, 'index': 'high'},\n",
      "           'to': '2019-01-02T21:30Z'},\n",
      "          {'from': '2019-01-02T21:30Z',\n",
      "           'intensity': {'actual': 343, 'forecast': 375, 'index': 'high'},\n",
      "           'to': '2019-01-02T22:00Z'},\n",
      "          {'from': '2019-01-02T22:00Z',\n",
      "           'intensity': {'actual': 329, 'forecast': 351, 'index': 'high'},\n",
      "           'to': '2019-01-02T22:30Z'},\n",
      "          {'from': '2019-01-02T22:30Z',\n",
      "           'intensity': {'actual': 320, 'forecast': 340, 'index': 'high'},\n",
      "           'to': '2019-01-02T23:00Z'},\n",
      "          {'from': '2019-01-02T23:00Z',\n",
      "           'intensity': {'actual': 315, 'forecast': 330, 'index': 'high'},\n",
      "           'to': '2019-01-02T23:30Z'},\n",
      "          {'from': '2019-01-02T23:30Z',\n",
      "           'intensity': {'actual': 316, 'forecast': 321, 'index': 'high'},\n",
      "           'to': '2019-01-03T00:00Z'},\n",
      "          {'from': '2019-01-03T00:00Z',\n",
      "           'intensity': {'actual': 317, 'forecast': 317, 'index': 'high'},\n",
      "           'to': '2019-01-03T00:30Z'},\n",
      "          {'from': '2019-01-03T00:30Z',\n",
      "           'intensity': {'actual': 315, 'forecast': 307, 'index': 'high'},\n",
      "           'to': '2019-01-03T01:00Z'},\n",
      "          {'from': '2019-01-03T01:00Z',\n",
      "           'intensity': {'actual': 314, 'forecast': 324, 'index': 'high'},\n",
      "           'to': '2019-01-03T01:30Z'},\n",
      "          {'from': '2019-01-03T01:30Z',\n",
      "           'intensity': {'actual': 321, 'forecast': 321, 'index': 'high'},\n",
      "           'to': '2019-01-03T02:00Z'},\n",
      "          {'from': '2019-01-03T02:00Z',\n",
      "           'intensity': {'actual': 328, 'forecast': 322, 'index': 'high'},\n",
      "           'to': '2019-01-03T02:30Z'},\n",
      "          {'from': '2019-01-03T02:30Z',\n",
      "           'intensity': {'actual': 329, 'forecast': 329, 'index': 'high'},\n",
      "           'to': '2019-01-03T03:00Z'},\n",
      "          {'from': '2019-01-03T03:00Z',\n",
      "           'intensity': {'actual': 329, 'forecast': 328, 'index': 'high'},\n",
      "           'to': '2019-01-03T03:30Z'},\n",
      "          {'from': '2019-01-03T03:30Z',\n",
      "           'intensity': {'actual': 328, 'forecast': 334, 'index': 'high'},\n",
      "           'to': '2019-01-03T04:00Z'},\n",
      "          {'from': '2019-01-03T04:00Z',\n",
      "           'intensity': {'actual': 327, 'forecast': 333, 'index': 'high'},\n",
      "           'to': '2019-01-03T04:30Z'},\n",
      "          {'from': '2019-01-03T04:30Z',\n",
      "           'intensity': {'actual': 332, 'forecast': 330, 'index': 'high'},\n",
      "           'to': '2019-01-03T05:00Z'},\n",
      "          {'from': '2019-01-03T05:00Z',\n",
      "           'intensity': {'actual': 339, 'forecast': 327, 'index': 'high'},\n",
      "           'to': '2019-01-03T05:30Z'},\n",
      "          {'from': '2019-01-03T05:30Z',\n",
      "           'intensity': {'actual': 340, 'forecast': 337, 'index': 'high'},\n",
      "           'to': '2019-01-03T06:00Z'},\n",
      "          {'from': '2019-01-03T06:00Z',\n",
      "           'intensity': {'actual': 347, 'forecast': 342, 'index': 'high'},\n",
      "           'to': '2019-01-03T06:30Z'},\n",
      "          {'from': '2019-01-03T06:30Z',\n",
      "           'intensity': {'actual': 355, 'forecast': 343, 'index': 'high'},\n",
      "           'to': '2019-01-03T07:00Z'},\n",
      "          {'from': '2019-01-03T07:00Z',\n",
      "           'intensity': {'actual': 371, 'forecast': 354, 'index': 'very high'},\n",
      "           'to': '2019-01-03T07:30Z'},\n",
      "          {'from': '2019-01-03T07:30Z',\n",
      "           'intensity': {'actual': 379, 'forecast': 362, 'index': 'very high'},\n",
      "           'to': '2019-01-03T08:00Z'},\n",
      "          {'from': '2019-01-03T08:00Z',\n",
      "           'intensity': {'actual': 392, 'forecast': 378, 'index': 'very high'},\n",
      "           'to': '2019-01-03T08:30Z'},\n",
      "          {'from': '2019-01-03T08:30Z',\n",
      "           'intensity': {'actual': 402, 'forecast': 376, 'index': 'very high'},\n",
      "           'to': '2019-01-03T09:00Z'},\n",
      "          {'from': '2019-01-03T09:00Z',\n",
      "           'intensity': {'actual': 409, 'forecast': 384, 'index': 'very high'},\n",
      "           'to': '2019-01-03T09:30Z'},\n",
      "          {'from': '2019-01-03T09:30Z',\n",
      "           'intensity': {'actual': 409, 'forecast': 402, 'index': 'very high'},\n",
      "           'to': '2019-01-03T10:00Z'},\n",
      "          {'from': '2019-01-03T10:00Z',\n",
      "           'intensity': {'actual': 407, 'forecast': 403, 'index': 'very high'},\n",
      "           'to': '2019-01-03T10:30Z'},\n",
      "          {'from': '2019-01-03T10:30Z',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           'intensity': {'actual': 407, 'forecast': 406, 'index': 'very high'},\n",
      "           'to': '2019-01-03T11:00Z'},\n",
      "          {'from': '2019-01-03T11:00Z',\n",
      "           'intensity': {'actual': 407, 'forecast': 404, 'index': 'very high'},\n",
      "           'to': '2019-01-03T11:30Z'},\n",
      "          {'from': '2019-01-03T11:30Z',\n",
      "           'intensity': {'actual': 404, 'forecast': 404, 'index': 'very high'},\n",
      "           'to': '2019-01-03T12:00Z'},\n",
      "          {'from': '2019-01-03T12:00Z',\n",
      "           'intensity': {'actual': 397, 'forecast': 404, 'index': 'very high'},\n",
      "           'to': '2019-01-03T12:30Z'}]}\n"
     ]
    }
   ],
   "source": [
    "data = json.loads(rrq.data)\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To create the DataFrame of the fetched data and print it, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-30T12:30Z</td>\n",
       "      <td>2018-12-30T13:00Z</td>\n",
       "      <td>{'forecast': 202, 'actual': 203, 'index': 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-30T13:00Z</td>\n",
       "      <td>2018-12-30T13:30Z</td>\n",
       "      <td>{'forecast': 201, 'actual': 208, 'index': 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-30T13:30Z</td>\n",
       "      <td>2018-12-30T14:00Z</td>\n",
       "      <td>{'forecast': 205, 'actual': 217, 'index': 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-30T14:00Z</td>\n",
       "      <td>2018-12-30T14:30Z</td>\n",
       "      <td>{'forecast': 214, 'actual': 225, 'index': 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-30T14:30Z</td>\n",
       "      <td>2018-12-30T15:00Z</td>\n",
       "      <td>{'forecast': 220, 'actual': 235, 'index': 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2019-01-03T10:00Z</td>\n",
       "      <td>2019-01-03T10:30Z</td>\n",
       "      <td>{'forecast': 403, 'actual': 407, 'index': 'ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2019-01-03T10:30Z</td>\n",
       "      <td>2019-01-03T11:00Z</td>\n",
       "      <td>{'forecast': 406, 'actual': 407, 'index': 'ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2019-01-03T11:00Z</td>\n",
       "      <td>2019-01-03T11:30Z</td>\n",
       "      <td>{'forecast': 404, 'actual': 407, 'index': 'ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2019-01-03T11:30Z</td>\n",
       "      <td>2019-01-03T12:00Z</td>\n",
       "      <td>{'forecast': 404, 'actual': 404, 'index': 'ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2019-01-03T12:00Z</td>\n",
       "      <td>2019-01-03T12:30Z</td>\n",
       "      <td>{'forecast': 404, 'actual': 397, 'index': 'ver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  from                 to  \\\n",
       "0    2018-12-30T12:30Z  2018-12-30T13:00Z   \n",
       "1    2018-12-30T13:00Z  2018-12-30T13:30Z   \n",
       "2    2018-12-30T13:30Z  2018-12-30T14:00Z   \n",
       "3    2018-12-30T14:00Z  2018-12-30T14:30Z   \n",
       "4    2018-12-30T14:30Z  2018-12-30T15:00Z   \n",
       "..                 ...                ...   \n",
       "187  2019-01-03T10:00Z  2019-01-03T10:30Z   \n",
       "188  2019-01-03T10:30Z  2019-01-03T11:00Z   \n",
       "189  2019-01-03T11:00Z  2019-01-03T11:30Z   \n",
       "190  2019-01-03T11:30Z  2019-01-03T12:00Z   \n",
       "191  2019-01-03T12:00Z  2019-01-03T12:30Z   \n",
       "\n",
       "                                             intensity  \n",
       "0    {'forecast': 202, 'actual': 203, 'index': 'mod...  \n",
       "1    {'forecast': 201, 'actual': 208, 'index': 'mod...  \n",
       "2    {'forecast': 205, 'actual': 217, 'index': 'mod...  \n",
       "3    {'forecast': 214, 'actual': 225, 'index': 'mod...  \n",
       "4    {'forecast': 220, 'actual': 235, 'index': 'mod...  \n",
       "..                                                 ...  \n",
       "187  {'forecast': 403, 'actual': 407, 'index': 'ver...  \n",
       "188  {'forecast': 406, 'actual': 407, 'index': 'ver...  \n",
       "189  {'forecast': 404, 'actual': 407, 'index': 'ver...  \n",
       "190  {'forecast': 404, 'actual': 404, 'index': 'ver...  \n",
       "191  {'forecast': 404, 'actual': 397, 'index': 'ver...  \n",
       "\n",
       "[192 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extracting Data from Local Files</h2>\n",
    "<br>\n",
    "In this exercise, we will extract data from different local files, such as a PDF file, an image file, an Excel file, and a Word file. Follow these steps to implement this exercise.\n",
    "<br>\n",
    "<br>\n",
    "<b>Import the <code>textract</code> library to extract text from a PDF file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "# textract does not work well with some files, such as pdf and png\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>qualification</th>\n",
       "      <th>additional qualification</th>\n",
       "      <th>other qualification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gangaram</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ganga</td>\n",
       "      <td>B.A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ram</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>M.Tech</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ramlal</td>\n",
       "      <td>B.Music</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diploma in Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name qualification additional qualification other qualification\n",
       "0  Gangaram        B.Tech                      NaN                 NaN\n",
       "1     Ganga          B.A.                      NaN                 NaN\n",
       "2       Ram        B.Tech                   M.Tech                 NaN\n",
       "3    Ramlal       B.Music                      NaN    Diploma in Music"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/sample_excel.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hamlet said to Horatio, There are more things in heaven and earth, Horatio, Than are dreamt of in your philosophy.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textract.process(\"data/sample_word_document.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Performing Various Operations on Local Files</h2>\n",
    "<br>\n",
    "In this exercise, we will perform various file operations, such as open, write, read, append, and close, on local files. Follow these steps to implement this exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>First, we create a text file and write a little content in it. Add the following code to implement this</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('data/sample_text.txt', 'w') \n",
    "fp.write(\"I'm in love text mining\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To add more text into an existing text file, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('data/sample_text.txt', 'a')\n",
    "fp.write(\"I am learning Natural Language Processing\\n\")\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To read the content from the text file, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm in love text mining\\n\", 'I am learning Natural Language Processing\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = open('data/sample_text.txt', 'r')\n",
    "fp.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To open text files with various encodings, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package unicode_samples to\n",
      "[nltk_data]     C:\\Users\\kleye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\unicode_samples.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\\n',\n",
       " '\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\\n',\n",
       " 'Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\\n',\n",
       " 'odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\\n',\n",
       " 'Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\\n',\n",
       " 'archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('unicode_samples')\n",
    "file_location = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')\n",
    "fp = open(file_location,'r', encoding='latin2')\n",
    "fp.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To read these files line by line, insert a new cell and add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open(file_location,'r', encoding='latin2'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To close the opened file, add the following code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
